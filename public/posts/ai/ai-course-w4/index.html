<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>AI Course 4주차 | 개발자이선생 AI</title>
<meta name="keywords" content="ai">
<meta name="description" content="3주차까지 AI의 이론을 배우고, 직접 모델을 구현하는 과정을 거쳤고,
[기본] HuggingFace
4주차에는 HuggingFace 플랫폼을 사용해서 모델을 학습하는 과정을 배웠다.
이 방법은 현업에서 많은 ML Engineer들이 실제로 사용하고 있는 방법이라고 하는데, 확실히 직접 Transformer 모델을 구현하는 것 보다 훨씬 코드가 간결해졌고,
출력 결과도 깔끔하고, wandb를 바로 사용할 수 있다는 것도 편리했다.
확실히 바닐라JS를 익히고, React를 사용하면 더 이해가 쉬운 것처럼
AI도 PyTorch로 직접 Transformer 모델을 구현해보고, 이후에 HuggingFace를 사용하니 더 이해가 쉬웠다.">
<meta name="author" content="">
<link rel="canonical" href="https://teacherssamko.github.io/tech-blog/posts/ai/ai-course-w4/">
<link crossorigin="anonymous" href="/tech-blog/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css" integrity="sha256-1vzSCk&#43;4bvpN&#43;sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://teacherssamko.github.io/tech-blog/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://teacherssamko.github.io/tech-blog/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://teacherssamko.github.io/tech-blog/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://teacherssamko.github.io/tech-blog/apple-touch-icon.png">
<link rel="mask-icon" href="https://teacherssamko.github.io/tech-blog/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://teacherssamko.github.io/tech-blog/posts/ai/ai-course-w4/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="https://teacherssamko.github.io/tech-blog/posts/ai/ai-course-w4/">
  <meta property="og:site_name" content="개발자이선생 AI">
  <meta property="og:title" content="AI Course 4주차">
  <meta property="og:description" content="3주차까지 AI의 이론을 배우고, 직접 모델을 구현하는 과정을 거쳤고,
[기본] HuggingFace 4주차에는 HuggingFace 플랫폼을 사용해서 모델을 학습하는 과정을 배웠다.
이 방법은 현업에서 많은 ML Engineer들이 실제로 사용하고 있는 방법이라고 하는데, 확실히 직접 Transformer 모델을 구현하는 것 보다 훨씬 코드가 간결해졌고, 출력 결과도 깔끔하고, wandb를 바로 사용할 수 있다는 것도 편리했다.
확실히 바닐라JS를 익히고, React를 사용하면 더 이해가 쉬운 것처럼 AI도 PyTorch로 직접 Transformer 모델을 구현해보고, 이후에 HuggingFace를 사용하니 더 이해가 쉬웠다.">
  <meta property="og:locale" content="ko-kr">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-01-10T00:00:00+00:00">
    <meta property="article:tag" content="Ai">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="AI Course 4주차">
<meta name="twitter:description" content="3주차까지 AI의 이론을 배우고, 직접 모델을 구현하는 과정을 거쳤고,
[기본] HuggingFace
4주차에는 HuggingFace 플랫폼을 사용해서 모델을 학습하는 과정을 배웠다.
이 방법은 현업에서 많은 ML Engineer들이 실제로 사용하고 있는 방법이라고 하는데, 확실히 직접 Transformer 모델을 구현하는 것 보다 훨씬 코드가 간결해졌고,
출력 결과도 깔끔하고, wandb를 바로 사용할 수 있다는 것도 편리했다.
확실히 바닐라JS를 익히고, React를 사용하면 더 이해가 쉬운 것처럼
AI도 PyTorch로 직접 Transformer 모델을 구현해보고, 이후에 HuggingFace를 사용하니 더 이해가 쉬웠다.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://teacherssamko.github.io/tech-blog/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "AI Course 4주차",
      "item": "https://teacherssamko.github.io/tech-blog/posts/ai/ai-course-w4/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "AI Course 4주차",
  "name": "AI Course 4주차",
  "description": "3주차까지 AI의 이론을 배우고, 직접 모델을 구현하는 과정을 거쳤고,\n[기본] HuggingFace 4주차에는 HuggingFace 플랫폼을 사용해서 모델을 학습하는 과정을 배웠다.\n이 방법은 현업에서 많은 ML Engineer들이 실제로 사용하고 있는 방법이라고 하는데, 확실히 직접 Transformer 모델을 구현하는 것 보다 훨씬 코드가 간결해졌고, 출력 결과도 깔끔하고, wandb를 바로 사용할 수 있다는 것도 편리했다.\n확실히 바닐라JS를 익히고, React를 사용하면 더 이해가 쉬운 것처럼 AI도 PyTorch로 직접 Transformer 모델을 구현해보고, 이후에 HuggingFace를 사용하니 더 이해가 쉬웠다.\n",
  "keywords": [
    "ai"
  ],
  "articleBody": "3주차까지 AI의 이론을 배우고, 직접 모델을 구현하는 과정을 거쳤고,\n[기본] HuggingFace 4주차에는 HuggingFace 플랫폼을 사용해서 모델을 학습하는 과정을 배웠다.\n이 방법은 현업에서 많은 ML Engineer들이 실제로 사용하고 있는 방법이라고 하는데, 확실히 직접 Transformer 모델을 구현하는 것 보다 훨씬 코드가 간결해졌고, 출력 결과도 깔끔하고, wandb를 바로 사용할 수 있다는 것도 편리했다.\n확실히 바닐라JS를 익히고, React를 사용하면 더 이해가 쉬운 것처럼 AI도 PyTorch로 직접 Transformer 모델을 구현해보고, 이후에 HuggingFace를 사용하니 더 이해가 쉬웠다.\n과제 MNLI 데이터셋을 사용해서, 두 문장 간의 논리적 관계를 판단하는 모델을 만드는 과제였다.\nEDA 및 데이터 전처리 학습 데이터:\n최대 길이: 396 평균 길이: 29.78 검증 데이터 (matched):\n최대 길이: 216 평균 길이: 29.18 학습 데이터 길이가 전반적으로 100 이하인 것을 확인할 수 있어서, 이보다 긴 데이터는 제외하고 학습시키는 방향으로 진행하기로 했다.\n학습 데이터:\n최대 길이: 127 평균 길이: 29.56 검증 데이터 (matched):\n최대 길이: 216 평균 길이: 29.18 학습데이터는 128 미만의 데이터만 필터링하고, 검증 데이터는 그대로 사용.\nHuggingFace 과제 전체 코드\n모델 학습 BERT 모델을 사용한 학습 결과\n학습 시간이 9시간 가까이 걸렸다.\nEpoch Training Loss Validation Loss Accuracy 1 0.553400 0.462073 0.818635 2 0.376100 0.441790 0.831019 3 0.265600 0.484720 0.831618 4 0.186600 0.561473 0.828825 5 0.133300 0.650474 0.826249 6 0.098100 0.735423 0.827205 7 0.074500 0.853703 0.824680 8 0.057800 0.892868 0.826950 9 0.045900 1.023744 0.826950 10 0.037200 1.082273 0.827142 3 epoch만에 최대 학습 정확도 83%를 달성하고, 이후에 점차 감소하는 것을 확인할 수 있었다.\ndistilBERT 모델을 사용한 학습\n비교를 위해 distilBERT 모델을 사용했고, distilBERT의 파라미터는 학습하지 않도록 설정했다. 이번에도 과적합이 발생할 것으로 예상되어 epoch을 5로 제한했다.\nfor param in model.distilbert.parameters(): param.requires_grad = False Epoch Training Loss Validation Loss Accuracy 1 1.088900 1.078951 0.408031 2 1.078700 1.071682 0.417248 3 1.075000 1.068300 0.422409 4 1.073000 1.066694 0.424908 5 1.072000 1.066206 0.426490 한 시간만에 학습이 됐지만, 과적합이 발생하지 않았고, 정확도는 42%로 매우 낮게 나왔다. distilBERT 자체의 한계라고 보기엔 차이가 너무 심하다고 생각되서, distilBERT의 파라미터도 학습을 시켜야겠다고 판단했다.\ndistilBERT의 파라미터도 학습한 결과\nEpoch Training Loss Validation Loss Accuracy 1 0.886300 0.806939 0.640874 2 0.768100 0.768995 0.666916 3 0.699400 0.752836 0.675359 4 0.642700 0.776968 0.674662 5 0.600300 0.785430 0.675512 distilBERT의 파라미터도 학습에 포함시켰더니, 정확도가 67%까지 올라갔다. 여전히 BERT 모델의 83%에는 미치지 못하지만, 학습 시간은 2시간 정도로 크게 단축되었다.\noverfitting이 발생하지 않았기에, epoch을 늘리면 더 높은 정확도를 달성할 수 있을 것으로 예상되었지만, 과제 통과 기준인 50%를 달성했기도 하고, colab credit 문제로 학습을 더이상 진행시키지는 않았다.\n[심화] OpenAI API OpenAI API를 사용해서 LLM을 사용하는 과제도 진행했는데, 이미 OpenAI API를 이용해서 챗봇도 만들었고, 이미지 생성도 하고 있기 때문에, API사용 자체는 익숙했고, Prompt작성도 익숙했지만,\n이번에는 LLM의 성능을 최대한 높일 수 있는 Prompting 전략을 좀 더 익히고, 이를 통해서 과제의 통과 기준을 채우는 것이 목표였다.\n과제 이 과제는 GPT-4o 모델을 사용해서 2023 수능 국어문제를 풀어보는 과제였다.\n데이터는 KICE Slayer AI korean 에서 제공하는 데이터를 사용했다.\nEDA 데이터는 아래와 같은 형태로 이루어져있었다.\n{ \"id\": \"2023_11_KICE_1-3\", \"paragraph\": \"사람들이 지속적으로 책을 읽는 이유 중 하나는 즐거움이다. 독서의 즐거움에는 여러 가지가 있겠지만 그 중심에는 ‘소통의 즐거움’이 있다.독자는 독서를 통해 책과 소통하는 즐거움을 경험한다. 독서는필자와 간접적으로 대화하는 소통 행위이다. 독자는 자신이 속한사회나 시대의 영향 아래 필자가 속해 있거나 드러내고자 하는 사회나 시대를 경험한다. 직접 경험하지 못했던 다양한 삶을 필자를 매개로 만나고 이해하면서 독자는 더 넓은 시야로 세계를바라볼 수 있다. 이때 같은 책을 읽은 독자라도 독자의 배경지식이나 관점 등의 독자 요인, 읽기 환경이나 과제 등의 상황 요인이 다르므로, 필자가 보여 주는 세계를 그대로 수용하지 않고 저마다 소통 과정에서 다른 의미를 구성할 수 있다.[A] (이러한 소통은 독자가 책의 내용에 대해 질문하고 답을 찾아내는 과정에서 가능해진다. 독자는 책에서 답을 찾는 질문, 독자 자신에게서 답을 찾는 질문 등을 제기할 수 있다. 전자의 경우 책에 명시된 내용에서 답을 발견할 수 있고, 책의 내용들을 관계 지으며 답에 해당하는 내용을 스스로 구성할 수도 있다. 또한 후자의 경우 책에는 없는 독자의 경험에서 답을 찾을 수 있다. 이런 질문들을 풍부히 생성하고 주체적으로 답을 찾을 때 소통의 즐거움은 더 커진다.)한편 독자는 ㉠ (다른 독자와 소통하는 즐거움을 경험할 수도 있다.) 책과의 소통을 통해 개인적으로 형성한 의미를 독서 모임이나 독서 동아리 등에서 다른 독자들과 나누는 일이 이에 해당한다. 비슷한 해석에 서로 공감하며 기존 인식을 강화하거나 관점의 차이를 확인하고 기존 인식을 조정하는 과정에서, 독자는자신의 인식을 심화 확장할 수 있다. 최근 소통 공간이 온라인으로 확대되면서 독서를 통해 다른 독자들과 소통하며 즐거움을누리는 양상이 더 다양해지고 있다. 자신의 독서 경험을 담은 글이나 동영상을 생산 공유함으로써, 책을 읽지 않은 타인이 책과 소통하도록 돕는 것도 책을 통한 소통의 즐거움을 나누는 일이다.\", \"type\": 0, \"problems\": [ { \"question\": \"윗글의 내용과 일치하지 않는 것은?\", \"choices\": [ \"같은 책을 읽은 독자라도 서로 다른 의미를 구성할 수 있다.\", \"다른 독자와의 소통은 독자가 인식의 폭을 확장하도록 돕는다\", \"독자는 직접 경험해 보지 못했던 다양한 삶을 책의 필자를 매개로 접할 수 있다.\", \"독자의 배경지식, 관점, 읽기 환경, 과제는 독자의 의미 구성에 영향을 주는 독자 요인이다.\", \"독자는 책을 읽을 때 자신이 속한 사회나 시대의 영향을 받으며 필자와 간접적으로 대화한다\" ], \"answer\": 4, \"score\": 2 }, { \"question\": \"다음은 학생이 독서 후 작성한 글의 일부이다. [A]를 바탕으로 ⓐ～ⓔ를 이해한 내용으로 가장 적절한 것은?\", \"question_plus\": \"ⓐ('음악 시간에 들었던 베토벤의 교향곡 \u003c합창\u003e이 위대한 작품인 이유는 무엇일까?'하는 생각)에, 베토벤에 대한 책을 빌렸다. 책에서는 기약만으로 구성됐던 교향곡에 성악을 결합헤 개성을 드러냈다는 점에서 ⓑ(이 곡이 낭만주의 음악의 특징을 보여 준다고 했다.) \u003c합창\u003e을 해설한 부분에 이어, 베토벤의 생애에 관한 뒷부분도 읽었는데, ⓒ(이 내용들을 종합해, 절망적 상황에서도 열정적으로 자신이 좋아하는 일을 했기에 교향곡 구성의 새로움을 보여 준 명작이 탄생했음을 알게 됐다.) 이후 ⓓ(내가 진정으로 좋아하는 일이 무엇인지 나에게 묻게 되었다.) ⓔ(글 쓰는 일에서 가장 큰 행복을 느꼈던 나를 발견)할 수 있었고, 나도 어떤 상황에서든 좋아하는 일을 계속해야겠다고 생각했다.\", \"choices\": [ \"ⓐ와 ⓑ에는 모두 ‘독자 자신에게서 답을 찾는 질문’이 나타난다.\", \"ⓒ와 ⓓ에는 모두 ‘책에 명시된 내용’에서 질문의 답을 찾아내는 모습이 나타난다.\", \"ⓐ에는 ‘책에서 답을 찾는 질문’이, ⓔ에는 그에 대한 답을 ‘독자의 경험’에서 찾아내는 모습이 나타난다.\", \"ⓑ에는 ‘책에서 답을 찾는 질문’이, ⓒ에는 그에 대한 답을 ‘책의 내용들을 관계 지으며’ 찾아내는 모습이 나타난다.\", \"ⓓ에는 ‘독자 자신에게서 답을 찾는 질문’이, ⓔ에는 그에 대한 답을 ‘독자의 경험’에서 찾아내는 모습이 나타난다.\" ], \"answer\": 5, \"score\": 3 }, { \"question\" : \"윗글을 읽고 ㉠에 대해 보인 반응으로 적절하지 않은 것은?\", \"choices\" : [ \"스스로 독서 계획을 세우고 자신에게 필요한 책을 찾아 개인적으로 읽는 과정에서 경험할 수 있겠군.\", \"독서 모임에서 서로 다른 관점을 확인하고 자신의 관점을 조정하는 과정에서 경험할 수 있겠군.\", \"개인적으로 형성한 의미를, 독서 동아리를 통해 심화하는 과정에서 경험할 수 있겠군.\", \"자신의 독서 경험을 담은 콘텐츠를 생산하고 공유하는 과정에서 경험할 수 있겠군.\", \"오프라인뿐 아니라 온라인 공간에서 해석을 나누는 과정에서도 경험할 수 있겠군.\" ], \"answer\": 1, \"score\": 2 } ] } prediction, parse_answer 함수 작성 문제를 풀고, 정답을 답하는 prediction 함수와 응답에서 정답을 parsing하는 parse_answer 함수를 작성하는 것이 핵심이었다.\nprompting에는 COT(Chain of Thought)를 사용했는데, 질문 전체를 한글로 작성하고, 마지막 COT만 영어(Let’s think step by step)로 제공했다. 이는 prompting 전략 중에서 COT를 영어로 작성하는 것이 우리말로 작성하는 것보다 성능이 좋게 나왔다는 것을 확인했기 때문이다. 벤치마크 결과\n답변의 형식을 지정해주는 방식의 성능은 조금 낮게 나왔는데, parsing을 하기 위해 답변의 형식을 지정해주면서 성능을 유지하기 위한 테스트를 많이 했으나, 결국 성능이 떨어지는 것을 확인했다. 그래서 일반적은 응답을 그대로 사용하는 방식으로 진행했다.\n내가 최종적으로 작성한 프롬프트에 대한 답변으로 대부분 응답의 마지막에 정답을 말하는 것이 확인되어서 parse_answer 함수에서는 마지막 문장에 있는 숫자를 정답으로 추출하는 방식으로 사용하였다.\n그리고, 오답인 문제에 한해서만 API응답 전문을 반환하도록 했는데, parsing에 실패한 경우는 전체 45문제 중에 단 한 건만 발생하였다.\nscore: 85\n최종적으로 85점을 기록했고, 이는 KICE Slayer AI korean 벤치마크 결과의 최고점과 같았다. 해당 벤치마크에서 최고점을 기록한 것은 역시 COT를 영어로 작성한 prompt였는데, COT자체가 정말 영향을 많이 끼친다는 것을 직접 확인할 수 있었다.\nOpenAI API 과제 전체 코드\n",
  "wordCount" : "1201",
  "inLanguage": "en",
  "datePublished": "2025-01-10T00:00:00Z",
  "dateModified": "2025-01-10T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://teacherssamko.github.io/tech-blog/posts/ai/ai-course-w4/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "개발자이선생 AI",
    "logo": {
      "@type": "ImageObject",
      "url": "https://teacherssamko.github.io/tech-blog/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://teacherssamko.github.io/tech-blog/" accesskey="h" title="개발자이선생 AI (Alt + H)">개발자이선생 AI</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      AI Course 4주차
    </h1>
    <div class="post-meta"><span title='2025-01-10 00:00:00 +0000 UTC'>January 10, 2025</span>&nbsp;·&nbsp;6 min

</div>
  </header> 
  <div class="post-content"><p>3주차까지 AI의 이론을 배우고, 직접 모델을 구현하는 과정을 거쳤고,</p>
<h2 id="기본-huggingface">[기본] HuggingFace<a hidden class="anchor" aria-hidden="true" href="#기본-huggingface">#</a></h2>
<p>4주차에는 HuggingFace 플랫폼을 사용해서 모델을 학습하는 과정을 배웠다.</p>
<p>이 방법은 현업에서 많은 ML Engineer들이 실제로 사용하고 있는 방법이라고 하는데, 확실히 직접 Transformer 모델을 구현하는 것 보다 훨씬 코드가 간결해졌고,
출력 결과도 깔끔하고, wandb를 바로 사용할 수 있다는 것도 편리했다.</p>
<p>확실히 바닐라JS를 익히고, React를 사용하면 더 이해가 쉬운 것처럼
AI도 PyTorch로 직접 Transformer 모델을 구현해보고, 이후에 HuggingFace를 사용하니 더 이해가 쉬웠다.</p>
<h3 id="과제">과제<a hidden class="anchor" aria-hidden="true" href="#과제">#</a></h3>
<p>MNLI 데이터셋을 사용해서, 두 문장 간의 논리적 관계를 판단하는 모델을 만드는 과제였다.</p>
<ol>
<li>EDA 및 데이터 전처리</li>
</ol>
<p>학습 데이터:</p>
<ul>
<li>최대 길이: 396</li>
<li>평균 길이: 29.78</li>
</ul>
<p>검증 데이터 (matched):</p>
<ul>
<li>최대 길이: 216</li>
<li>평균 길이: 29.18</li>
</ul>
<p><img alt="EDA" loading="lazy" src="images/ai-course-w4-f1.png"></p>
<blockquote>
<p>학습 데이터 길이가 전반적으로 100 이하인 것을 확인할 수 있어서, 이보다 긴 데이터는 제외하고 학습시키는 방향으로 진행하기로 했다.</p>
</blockquote>
<p>학습 데이터:</p>
<ul>
<li>최대 길이: 127</li>
<li>평균 길이: 29.56</li>
</ul>
<p>검증 데이터 (matched):</p>
<ul>
<li>최대 길이: 216</li>
<li>평균 길이: 29.18</li>
</ul>
<p><img alt="Preprocessed Data" loading="lazy" src="images/ai-course-w4-f2.png"></p>
<p>학습데이터는 128 미만의 데이터만 필터링하고, 검증 데이터는 그대로 사용.</p>
<p><a href="https://github.com/teacherSsamko/DL-study/blob/main/%08w4_1.ipynb">HuggingFace 과제 전체 코드</a></p>
<ol start="2">
<li>모델 학습</li>
</ol>
<p><strong>BERT 모델을 사용한 학습 결과</strong></p>
<blockquote>
<p>학습 시간이 9시간 가까이 걸렸다.</p>
</blockquote>
<table>
  <thead>
      <tr>
          <th>Epoch</th>
          <th>Training Loss</th>
          <th>Validation Loss</th>
          <th>Accuracy</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>1</td>
          <td>0.553400</td>
          <td>0.462073</td>
          <td>0.818635</td>
      </tr>
      <tr>
          <td>2</td>
          <td>0.376100</td>
          <td>0.441790</td>
          <td>0.831019</td>
      </tr>
      <tr>
          <td>3</td>
          <td>0.265600</td>
          <td>0.484720</td>
          <td>0.831618</td>
      </tr>
      <tr>
          <td>4</td>
          <td>0.186600</td>
          <td>0.561473</td>
          <td>0.828825</td>
      </tr>
      <tr>
          <td>5</td>
          <td>0.133300</td>
          <td>0.650474</td>
          <td>0.826249</td>
      </tr>
      <tr>
          <td>6</td>
          <td>0.098100</td>
          <td>0.735423</td>
          <td>0.827205</td>
      </tr>
      <tr>
          <td>7</td>
          <td>0.074500</td>
          <td>0.853703</td>
          <td>0.824680</td>
      </tr>
      <tr>
          <td>8</td>
          <td>0.057800</td>
          <td>0.892868</td>
          <td>0.826950</td>
      </tr>
      <tr>
          <td>9</td>
          <td>0.045900</td>
          <td>1.023744</td>
          <td>0.826950</td>
      </tr>
      <tr>
          <td>10</td>
          <td>0.037200</td>
          <td>1.082273</td>
          <td>0.827142</td>
      </tr>
  </tbody>
</table>
<p>3 epoch만에 최대 학습 정확도 83%를 달성하고, 이후에 점차 감소하는 것을 확인할 수 있었다.</p>
<p><strong>distilBERT 모델을 사용한 학습</strong></p>
<p>비교를 위해 distilBERT 모델을 사용했고, distilBERT의 파라미터는 학습하지 않도록 설정했다. 이번에도 과적합이 발생할 것으로 예상되어 epoch을 5로 제한했다.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">for</span> param <span style="color:#f92672">in</span> model<span style="color:#f92672">.</span>distilbert<span style="color:#f92672">.</span>parameters():
</span></span><span style="display:flex;"><span>  param<span style="color:#f92672">.</span>requires_grad <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>
</span></span></code></pre></div><table>
  <thead>
      <tr>
          <th>Epoch</th>
          <th>Training Loss</th>
          <th>Validation Loss</th>
          <th>Accuracy</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>1</td>
          <td>1.088900</td>
          <td>1.078951</td>
          <td>0.408031</td>
      </tr>
      <tr>
          <td>2</td>
          <td>1.078700</td>
          <td>1.071682</td>
          <td>0.417248</td>
      </tr>
      <tr>
          <td>3</td>
          <td>1.075000</td>
          <td>1.068300</td>
          <td>0.422409</td>
      </tr>
      <tr>
          <td>4</td>
          <td>1.073000</td>
          <td>1.066694</td>
          <td>0.424908</td>
      </tr>
      <tr>
          <td>5</td>
          <td>1.072000</td>
          <td>1.066206</td>
          <td>0.426490</td>
      </tr>
  </tbody>
</table>
<p>한 시간만에 학습이 됐지만, 과적합이 발생하지 않았고, 정확도는 42%로 매우 낮게 나왔다. distilBERT 자체의 한계라고 보기엔 차이가 너무 심하다고 생각되서, distilBERT의 파라미터도 학습을 시켜야겠다고 판단했다.</p>
<p><strong>distilBERT의 파라미터도 학습한 결과</strong></p>
<table>
  <thead>
      <tr>
          <th>Epoch</th>
          <th>Training Loss</th>
          <th>Validation Loss</th>
          <th>Accuracy</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>1</td>
          <td>0.886300</td>
          <td>0.806939</td>
          <td>0.640874</td>
      </tr>
      <tr>
          <td>2</td>
          <td>0.768100</td>
          <td>0.768995</td>
          <td>0.666916</td>
      </tr>
      <tr>
          <td>3</td>
          <td>0.699400</td>
          <td>0.752836</td>
          <td>0.675359</td>
      </tr>
      <tr>
          <td>4</td>
          <td>0.642700</td>
          <td>0.776968</td>
          <td>0.674662</td>
      </tr>
      <tr>
          <td>5</td>
          <td>0.600300</td>
          <td>0.785430</td>
          <td>0.675512</td>
      </tr>
  </tbody>
</table>
<p>distilBERT의 파라미터도 학습에 포함시켰더니, 정확도가 67%까지 올라갔다. 여전히 BERT 모델의 83%에는 미치지 못하지만, 학습 시간은 2시간 정도로 크게 단축되었다.</p>
<p>overfitting이 발생하지 않았기에, epoch을 늘리면 더 높은 정확도를 달성할 수 있을 것으로 예상되었지만, 과제 통과 기준인 50%를 달성했기도 하고, colab credit 문제로 학습을 더이상 진행시키지는 않았다.</p>
<h2 id="심화-openai-api">[심화] OpenAI API<a hidden class="anchor" aria-hidden="true" href="#심화-openai-api">#</a></h2>
<p>OpenAI API를 사용해서 LLM을 사용하는 과제도 진행했는데, 이미 OpenAI API를 이용해서 챗봇도 만들었고, 이미지 생성도 하고 있기 때문에, API사용 자체는 익숙했고, Prompt작성도 익숙했지만,</p>
<p>이번에는 LLM의 성능을 최대한 높일 수 있는 Prompting 전략을 좀 더 익히고, 이를 통해서 과제의 통과 기준을 채우는 것이 목표였다.</p>
<h3 id="과제-1">과제<a hidden class="anchor" aria-hidden="true" href="#과제-1">#</a></h3>
<p>이 과제는 GPT-4o 모델을 사용해서 2023 수능 국어문제를 풀어보는 과제였다.</p>
<p>데이터는 <a href="https://github.com/NomaDamas/KICE_slayer_AI_Korean">KICE Slayer AI korean</a> 에서 제공하는 데이터를 사용했다.</p>
<ol>
<li>EDA</li>
</ol>
<p>데이터는 아래와 같은 형태로 이루어져있었다.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;id&#34;</span>: <span style="color:#e6db74">&#34;2023_11_KICE_1-3&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;paragraph&#34;</span>: <span style="color:#e6db74">&#34;사람들이 지속적으로 책을 읽는 이유 중 하나는 즐거움이다. 독서의 즐거움에는 여러 가지가 있겠지만 그 중심에는 ‘소통의 즐거움’이 있다.독자는 독서를 통해 책과 소통하는 즐거움을 경험한다. 독서는필자와 간접적으로 대화하는 소통 행위이다. 독자는 자신이 속한사회나 시대의 영향 아래 필자가 속해 있거나 드러내고자 하는 사회나 시대를 경험한다. 직접 경험하지 못했던 다양한 삶을 필자를 매개로 만나고 이해하면서 독자는 더 넓은 시야로 세계를바라볼 수 있다. 이때 같은 책을 읽은 독자라도 독자의 배경지식이나 관점 등의 독자 요인, 읽기 환경이나 과제 등의 상황 요인이 다르므로, 필자가 보여 주는 세계를 그대로 수용하지 않고 저마다 소통 과정에서 다른 의미를 구성할 수 있다.[A] (이러한 소통은 독자가 책의 내용에 대해 질문하고 답을 찾아내는 과정에서 가능해진다. 독자는 책에서 답을 찾는 질문, 독자 자신에게서 답을 찾는 질문 등을 제기할 수 있다. 전자의 경우 책에 명시된 내용에서 답을 발견할 수 있고, 책의 내용들을 관계 지으며 답에 해당하는 내용을 스스로 구성할 수도 있다. 또한 후자의 경우 책에는 없는 독자의 경험에서 답을 찾을 수 있다. 이런 질문들을 풍부히 생성하고 주체적으로 답을 찾을 때 소통의 즐거움은 더 커진다.)한편 독자는 ㉠ (다른 독자와 소통하는 즐거움을 경험할 수도 있다.) 책과의 소통을 통해 개인적으로 형성한 의미를 독서 모임이나 독서 동아리 등에서 다른 독자들과 나누는 일이 이에 해당한다. 비슷한 해석에 서로 공감하며 기존 인식을 강화하거나 관점의 차이를 확인하고 기존 인식을 조정하는 과정에서, 독자는자신의 인식을 심화 확장할 수 있다. 최근 소통 공간이 온라인으로 확대되면서 독서를 통해 다른 독자들과 소통하며 즐거움을누리는 양상이 더 다양해지고 있다. 자신의 독서 경험을 담은 글이나 동영상을 생산 공유함으로써, 책을 읽지 않은 타인이 책과 소통하도록 돕는 것도 책을 통한 소통의 즐거움을 나누는 일이다.&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;problems&#34;</span>: [
</span></span><span style="display:flex;"><span>      {
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;question&#34;</span>: <span style="color:#e6db74">&#34;윗글의 내용과 일치하지 않는 것은?&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;choices&#34;</span>: [
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;같은 책을 읽은 독자라도 서로 다른 의미를 구성할 수 있다.&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;다른 독자와의 소통은 독자가 인식의 폭을 확장하도록 돕는다&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;독자는 직접 경험해 보지 못했던 다양한 삶을 책의 필자를 매개로 접할 수 있다.&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;독자의 배경지식, 관점, 읽기 환경, 과제는 독자의 의미 구성에 영향을 주는 독자 요인이다.&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;독자는 책을 읽을 때 자신이 속한 사회나 시대의 영향을 받으며 필자와 간접적으로 대화한다&#34;</span>
</span></span><span style="display:flex;"><span>        ],
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;answer&#34;</span>: <span style="color:#ae81ff">4</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;score&#34;</span>: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>      },
</span></span><span style="display:flex;"><span>      {
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;question&#34;</span>: <span style="color:#e6db74">&#34;다음은 학생이 독서 후 작성한 글의 일부이다. [A]를 바탕으로 ⓐ～ⓔ를 이해한 내용으로 가장 적절한 것은?&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;question_plus&#34;</span>: <span style="color:#e6db74">&#34;ⓐ(&#39;음악 시간에 들었던 베토벤의 교향곡 &lt;합창&gt;이 위대한 작품인 이유는 무엇일까?&#39;하는 생각)에, 베토벤에 대한 책을 빌렸다. 책에서는 기약만으로 구성됐던 교향곡에 성악을 결합헤 개성을 드러냈다는 점에서 ⓑ(이 곡이 낭만주의 음악의 특징을 보여 준다고 했다.) &lt;합창&gt;을 해설한 부분에 이어, 베토벤의 생애에 관한 뒷부분도 읽었는데, ⓒ(이 내용들을 종합해, 절망적 상황에서도 열정적으로 자신이 좋아하는 일을 했기에 교향곡 구성의 새로움을 보여 준 명작이 탄생했음을 알게 됐다.) 이후 ⓓ(내가 진정으로 좋아하는 일이 무엇인지 나에게 묻게 되었다.) ⓔ(글 쓰는 일에서 가장 큰 행복을 느꼈던 나를 발견)할 수 있었고, 나도 어떤 상황에서든 좋아하는 일을 계속해야겠다고 생각했다.&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;choices&#34;</span>: [
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;ⓐ와 ⓑ에는 모두 ‘독자 자신에게서 답을 찾는 질문’이 나타난다.&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;ⓒ와 ⓓ에는 모두 ‘책에 명시된 내용’에서 질문의 답을 찾아내는 모습이 나타난다.&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;ⓐ에는 ‘책에서 답을 찾는 질문’이, ⓔ에는 그에 대한 답을 ‘독자의 경험’에서 찾아내는 모습이 나타난다.&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;ⓑ에는 ‘책에서 답을 찾는 질문’이, ⓒ에는 그에 대한 답을 ‘책의 내용들을 관계 지으며’ 찾아내는 모습이 나타난다.&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;ⓓ에는 ‘독자 자신에게서 답을 찾는 질문’이, ⓔ에는 그에 대한 답을 ‘독자의 경험’에서 찾아내는 모습이 나타난다.&#34;</span>
</span></span><span style="display:flex;"><span>        ],
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;answer&#34;</span>: <span style="color:#ae81ff">5</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;score&#34;</span>: <span style="color:#ae81ff">3</span>
</span></span><span style="display:flex;"><span>      },
</span></span><span style="display:flex;"><span>      {
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;question&#34;</span> : <span style="color:#e6db74">&#34;윗글을 읽고 ㉠에 대해 보인 반응으로 적절하지 않은 것은?&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;choices&#34;</span> : [
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;스스로 독서 계획을 세우고 자신에게 필요한 책을 찾아 개인적으로 읽는 과정에서 경험할 수 있겠군.&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;독서 모임에서 서로 다른 관점을 확인하고 자신의 관점을 조정하는 과정에서 경험할 수 있겠군.&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;개인적으로 형성한 의미를, 독서 동아리를 통해 심화하는 과정에서 경험할 수 있겠군.&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;자신의 독서 경험을 담은 콘텐츠를 생산하고 공유하는 과정에서 경험할 수 있겠군.&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;오프라인뿐 아니라 온라인 공간에서 해석을 나누는 과정에서도 경험할 수 있겠군.&#34;</span>
</span></span><span style="display:flex;"><span>        ],
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;answer&#34;</span>: <span style="color:#ae81ff">1</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;score&#34;</span>: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>  }
</span></span></code></pre></div><ol start="2">
<li>prediction, parse_answer 함수 작성</li>
</ol>
<p>문제를 풀고, 정답을 답하는 prediction 함수와 응답에서 정답을 parsing하는 parse_answer 함수를 작성하는 것이 핵심이었다.</p>
<p>prompting에는 COT(Chain of Thought)를 사용했는데, 질문 전체를 한글로 작성하고, 마지막 COT만 영어(Let&rsquo;s think step by step)로 제공했다. 이는 prompting 전략 중에서 COT를 영어로 작성하는 것이 우리말로 작성하는 것보다 성능이 좋게 나왔다는 것을 확인했기 때문이다. <a href="https://github.com/NomaDamas/KICE_slayer_AI_Korean/tree/master#vii-%EB%B2%A4%EC%B9%98%EB%A7%88%ED%81%AC-%EA%B2%B0%EA%B3%BC">벤치마크 결과</a></p>
<p>답변의 형식을 지정해주는 방식의 성능은 조금 낮게 나왔는데, parsing을 하기 위해 답변의 형식을 지정해주면서 성능을 유지하기 위한 테스트를 많이 했으나, 결국 성능이 떨어지는 것을 확인했다. 그래서 일반적은 응답을 그대로 사용하는 방식으로 진행했다.</p>
<p>내가 최종적으로 작성한 프롬프트에 대한 답변으로 대부분 응답의 마지막에 정답을 말하는 것이 확인되어서 parse_answer 함수에서는 마지막 문장에 있는 숫자를 정답으로 추출하는 방식으로 사용하였다.</p>
<p>그리고, 오답인 문제에 한해서만 API응답 전문을 반환하도록 했는데, parsing에 실패한 경우는 전체 45문제 중에 단 한 건만 발생하였다.</p>
<p><code>score: 85</code></p>
<p>최종적으로 85점을 기록했고, 이는 KICE Slayer AI korean 벤치마크 결과의 최고점과 같았다. 해당 벤치마크에서 최고점을 기록한 것은 역시 COT를 영어로 작성한 prompt였는데, COT자체가 정말 영향을 많이 끼친다는 것을 직접 확인할 수 있었다.</p>
<p><a href="https://github.com/teacherSsamko/DL-study/blob/main/w4_2.ipynb">OpenAI API 과제 전체 코드</a></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://teacherssamko.github.io/tech-blog/tags/ai/">Ai</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://teacherssamko.github.io/tech-blog/">개발자이선생 AI</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
